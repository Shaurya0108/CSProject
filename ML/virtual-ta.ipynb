{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow has access to the following devices:\n",
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "TensorFlow version: 2.13.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging,\n",
    ")\n",
    "from peft import LoraConfig, PeftModel\n",
    "from trl import SFTTrainer\n",
    "\n",
    "# Check for TensorFlow GPU access\n",
    "print(f\"TensorFlow has access to the following devices:\\n{tf.config.list_physical_devices()}\")\n",
    "\n",
    "# See TensorFlow version\n",
    "print(f\"TensorFlow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cd \"/Users/rubenmathew/Desktop/UTD/CS 4485/CSProject.nosync/ML/llama2/llama.cpp\"\n",
    "# !conda activate MLTA\n",
    "# !./main -m ./models/7B/ggml-model-q4_0.bin -n 1024 --repeat_penalty 1.0 --color -i -r \"Student:\" -f ./prompts/ta-chat.txt\n",
    "# !./main -m ./models/13B/ggml-model-q4_0.bin -n 1024 --temp 0.5 -s 1337 --repeat_penalty 1.1 --keep 130 --color -i -r \"Student:\" -f ./prompts/ta-chat.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Zero-Shot Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'how much of my grade is the final?',\n",
       " 'labels': ['Grading',\n",
       "  'Asymptomatic analysis',\n",
       "  'Proofs',\n",
       "  'Assignment Details',\n",
       "  'Greedy Methods',\n",
       "  'Design',\n",
       "  'Sorting',\n",
       "  'Professor Contact Info',\n",
       "  'Searching',\n",
       "  'Class Location',\n",
       "  'Course Description',\n",
       "  'Data Structures',\n",
       "  'Dynamic Programming',\n",
       "  'Class Time'],\n",
       " 'scores': [0.5714775919914246,\n",
       "  0.07328278571367264,\n",
       "  0.03942479193210602,\n",
       "  0.036618027836084366,\n",
       "  0.03529990464448929,\n",
       "  0.032818250358104706,\n",
       "  0.030507437884807587,\n",
       "  0.030034111812710762,\n",
       "  0.02965698204934597,\n",
       "  0.02943132072687149,\n",
       "  0.027783405035734177,\n",
       "  0.022871626541018486,\n",
       "  0.02200988680124283,\n",
       "  0.0187838152050972]}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import accelerate\n",
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "text_to_classify = \"how much of my grade is the final?\"\n",
    "candidate_labels = [\"Sorting\", \"Searching\", \"Design\", \"Data Structures\", \"Proofs\", \"Asymptomatic analysis\", \"Dynamic Programming\", \"Greedy Methods\", \"Grading\", \"Course Description\", \"Class Time\", \"Assignment Details\", \"Class Location\", \"Professor Contact Info\"]\n",
    "syllabus_labels = [\"Grading\", \"Course Description\", \"Assignment Details\", \"Class Time\", \"Class Location\", \"Professor Contact Info\"]\n",
    "\n",
    "classifier(text_to_classify, candidate_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import accelerate\n",
    "from transformers import pipeline\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large-mnli\")\n",
    "gptq_config = GPTQConfig(bits=4, dataset = \"c4\", tokenizer=tokenizer)\n",
    "\n",
    "text_to_classify = \"how much of my grade is the final?\"\n",
    "candidate_labels = [\"Sorting\", \"Searching\", \"Design\", \"Data Structures\", \"Proofs\", \"Asymptomatic analysis\", \"Dynamic Programming\", \"Greedy Methods\", \"Grading\", \"Course Description\", \"Class Time\", \"Assignment Details\", \"Class Location\", \"Professor Contact Info\"]\n",
    "syllabus_labels = [\"Grading\", \"Course Description\", \"Assignment Details\", \"Class Time\", \"Class Location\", \"Professor Contact Info\"]\n",
    "\n",
    "classifier(text_to_classify, candidate_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b157ed6dda5e454da2d5132932157d9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e5a33519aa24e00a0840bd104fb931d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dba040da832d4ac294ebdc823997fad1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "'validation'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/rubenmathew/Desktop/UTD/CS 4485/CSProject.nosync/ML/virtual-ta.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rubenmathew/Desktop/UTD/CS%204485/CSProject.nosync/ML/virtual-ta.ipynb#X22sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# Simulate the few-shot regime by sampling 8 examples per class\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rubenmathew/Desktop/UTD/CS%204485/CSProject.nosync/ML/virtual-ta.ipynb#X22sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m train_dataset \u001b[39m=\u001b[39m sample_dataset(dataset[\u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m], label_column\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mclass\u001b[39m\u001b[39m\"\u001b[39m, num_samples\u001b[39m=\u001b[39m\u001b[39m8\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/rubenmathew/Desktop/UTD/CS%204485/CSProject.nosync/ML/virtual-ta.ipynb#X22sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m eval_dataset \u001b[39m=\u001b[39m dataset[\u001b[39m\"\u001b[39;49m\u001b[39mvalidation\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rubenmathew/Desktop/UTD/CS%204485/CSProject.nosync/ML/virtual-ta.ipynb#X22sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m exit()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rubenmathew/Desktop/UTD/CS%204485/CSProject.nosync/ML/virtual-ta.ipynb#X22sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# Load a SetFit model from Hub\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/MLTA/lib/python3.11/site-packages/datasets/dataset_dict.py:59\u001b[0m, in \u001b[0;36mDatasetDict.__getitem__\u001b[0;34m(self, k)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, k) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dataset:\n\u001b[1;32m     58\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(k, (\u001b[39mstr\u001b[39m, NamedSplit)) \u001b[39mor\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m---> 59\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__getitem__\u001b[39;49m(k)\n\u001b[1;32m     60\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     61\u001b[0m         available_suggested_splits \u001b[39m=\u001b[39m [\n\u001b[1;32m     62\u001b[0m             split \u001b[39mfor\u001b[39;00m split \u001b[39min\u001b[39;00m (Split\u001b[39m.\u001b[39mTRAIN, Split\u001b[39m.\u001b[39mTEST, Split\u001b[39m.\u001b[39mVALIDATION) \u001b[39mif\u001b[39;00m split \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\n\u001b[1;32m     63\u001b[0m         ]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'validation'"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from sentence_transformers.losses import CosineSimilarityLoss\n",
    "\n",
    "from setfit import SetFitModel, SetFitTrainer, sample_dataset\n",
    "\n",
    "\n",
    "# Load a dataset from the Hugging Face Hub\n",
    "dataset = load_dataset(\"csv\", data_files=\"./mock-data/classification.csv\")\n",
    "\n",
    "# Simulate the few-shot regime by sampling 8 examples per class\n",
    "train_dataset = sample_dataset(dataset[\"train\"], label_column=\"class\", num_samples=8)\n",
    "eval_dataset = dataset[\"validation\"]\n",
    "\n",
    "exit()\n",
    "\n",
    "# Load a SetFit model from Hub\n",
    "model = SetFitModel.from_pretrained(\"facebook/bart-large-mnli\")\n",
    "\n",
    "# Create trainer\n",
    "trainer = SetFitTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    loss_class=CosineSimilarityLoss,\n",
    "    metric=\"accuracy\",\n",
    "    batch_size=16,\n",
    "    num_iterations=20, # The number of text pairs to generate for contrastive learning\n",
    "    num_epochs=1, # The number of epochs to use for contrastive learning\n",
    "    column_mapping={\"sentence\": \"text\", \"label\": \"label\"} # Map dataset columns to text/label expected by trainer\n",
    ")\n",
    "\n",
    "# Train and evaluate\n",
    "trainer.train()\n",
    "metrics = trainer.evaluate()\n",
    "\n",
    "# Push model to the Hub\n",
    "# trainer.push_to_hub(\"my-awesome-setfit-model\")\n",
    "\n",
    "# Download from Hub and run inference\n",
    "# model = SetFitModel.from_pretrained(\"lewtun/my-awesome-setfit-model\")\n",
    "# Run inference\n",
    "# preds = model([\"i loved the spiderman movie!\", \"pineapple on pizza is the worst 🤮\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tune Zero-Shot Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset, load_metric\n",
    "import random\n",
    "\n",
    "\n",
    "def shuffle_df(old_df: pd.DataFrame, cycles: int = 1) -> pd.DataFrame:\n",
    "  for i in range(cycles):\n",
    "    new_df = old_df.sample(frac=1).reset_index(drop=True)\n",
    "  return new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.empty_cache() # You may use this command to clear your cache\n",
    "# torch.cuda.is_available() # You may use this command to check if you have gpu or not\n",
    "\n",
    "org_df = pd.read_csv(\"./mock-data/classification.csv\")\n",
    "\n",
    "# Shuffle the data\n",
    "df = shuffle_df(org_df, 100)\n",
    "print(df)\n",
    "\n",
    "# Split the data into train and test portions\n",
    "train_percentage = 0.8\n",
    "train_portion = int(train_percentage * len(df))\n",
    "test_portion = len(df) - train_portion\n",
    "\n",
    "df_train = df.head(train_portion)\n",
    "df_test = df.tail(test_portion)\n",
    "\n",
    "\n",
    "# Convert to Dataset objects\n",
    "train_ds = Dataset.from_pandas(df_train, split=\"train\")\n",
    "test_ds = Dataset.from_pandas(df_test, split=\"test\")\n",
    "\n",
    "label_to_int = {(k,v) for v,k in enumerate(candidate_labels)}\n",
    "template = \"{}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartTokenizerFast\n",
    "\n",
    "tokenizer = BartTokenizerFast.from_pretrained('facebook/bart-large-mnli')\n",
    "\n",
    "def create_input_sequence(sample):\n",
    "\ttext = sample[\"text\"]\n",
    "\tlabel = sample[\"class\"][0]\n",
    "\tcontradiction_label = random.choice([x for x in label_to_int if x != label])\n",
    "\tencoded_sequence = tokenizer(text * 2, [template.format(label), template.format(contradiction_label)], truncation = True, padding = 'max_length')\n",
    "\tencoded_sequence[\"labels\"] = [2, 0]\n",
    "\tencoded_sequence[\"input_sentence\"] = tokenizer.batch_decode(encoded_sequence.input_ids)\n",
    "\treturn encoded_sequence\n",
    "\n",
    "\n",
    "train_dataset = train_ds.map(create_input_sequence, batched = True, batch_size = 1, remove_columns = [\"class\", \"text\"])\n",
    "test_dataset = test_ds.map(create_input_sequence, batched = True, batch_size = 1, remove_columns = [\"class\", \"text\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartForSequenceClassification, Trainer, TrainingArguments, EvalPrediction\n",
    "import numpy as np\n",
    "\n",
    "def compute_metrics(p: EvalPrediction):\n",
    "\tmetric_acc = load_metric(\"accuracy\")\n",
    "\tmetric_f1 = load_metric(\"f1\")\n",
    "\tpreds = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n",
    "\tpreds = np.argmax(preds, axis = 1)\n",
    "\tresult = {}\n",
    "\tresult[\"accuracy\"] = metric_acc.compute(predictions = preds, references = p.label_ids)[\"accuracy\"]\n",
    "\tresult[\"f1\"] = metric_f1.compute(predictions = preds, references = p.label_ids, average = 'macro')[\"f1\"]\n",
    "\treturn result\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "\toutput_dir = \"./ZSC_Models\",      # Output directory\n",
    "\tnum_train_epochs = 32,             # Total number of training epochs\n",
    "\tper_device_train_batch_size = 16,  # Batch size per device during training\n",
    "\tper_device_eval_batch_size = 64,   # Batch size for evaluation\n",
    "\twarmup_steps = 500,                # Number of warmup steps for learning rate scheduler\n",
    "\tweight_decay = 0.01,               # Strength of weight decay\n",
    ")\n",
    "\n",
    "model = BartForSequenceClassification.from_pretrained(\"facebook/bart-large-mnli\", num_labels = len(label_to_int), ignore_mismatched_sizes = True)\n",
    "\n",
    "trainer = Trainer(\n",
    "\tmodel = model,                     # The instantiated model to be trained\n",
    "\targs = training_args,              # Training arguments, defined above\n",
    "\tcompute_metrics = compute_metrics, # A function to compute the metrics\n",
    "\ttrain_dataset = train_dataset,     # Training dataset\n",
    "\teval_dataset = test_dataset,       # Evaluation dataset\n",
    "\ttokenizer = tokenizer              # The tokenizer that was used\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "trainer.evaluate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLTA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
